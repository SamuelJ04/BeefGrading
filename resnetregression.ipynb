{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model for USDA Beef Grading\n",
    "\n",
    "This model will use pytoch and resnet to make a CNN regression model (convolutional neural network)\n",
    "hay que mantener 5 pasos\n",
    "1. cargando imagenes y procesarlos\n",
    "2. modificar el modelo resnet para la regresion\n",
    "3. entrenar el model\n",
    "4. evaluar modelo (root mean square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torchvision.models import ResNet18_Weights, VGG16_Weights, AlexNet_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder =  \"Data/Cleaned JPEG Images\"\n",
    "training_folders = [\n",
    "    \"Cargill Dodge 07 20 22 Plant\", \n",
    "    \"Cargill Fort Morgan 03 28 22 Plant\",\n",
    "    \"Cargill Schuyler 04 01 22 Plant\",\n",
    "    \"Cargill Fort Morgan 07 15 22 Plant\"\n",
    "]\n",
    "\n",
    "testing_folders= [\n",
    "    \"Cargill Friona 07 18 22 Plant\",\n",
    "    \"Cargill Schuyler 07 18 22 Plant\",\n",
    "    \"Cargill Fort Morgan 05 12 22 Plant\",\n",
    "]\n",
    "#df = pd.read_excel(excel_path)\n",
    "\n",
    "#df.columns = df.columns.str.strip()\n",
    "#ID_to_score = dict(zip(df['CarcassId'], df['Average']))\n",
    "#ID_to_score = {f\"{carcass_id}.jpg\": avg for carcass_id, avg in zip(df['ID'], df['AVG'])}\n",
    "\n",
    "#print(ID_to_score.keys())\n",
    "\n",
    "def DataPrepare(root_folder, input_folders):\n",
    "    all_image_addresses= []\n",
    "    all_Scores = []\n",
    "    total_image_number = 0\n",
    "    for i in range((len(input_folders))):\n",
    "        img_folder_name = root_folder + \"/\" +  input_folders[i] + \"/Images/\"\n",
    "        Scores_name = root_folder + \"/\" + input_folders[i] + \"/data.xlsx\"\n",
    "        df = pd.read_excel(Scores_name)\n",
    "        for _, _, files in os.walk(img_folder_name):\n",
    "            for filename in files:\n",
    "                total_image_number += 1\n",
    "                all_image_addresses.append(img_folder_name + filename)\n",
    "                Score_value = df.at[int(df.index[df['ID'] == filename[0:-4]][0]), 'AVG']\n",
    "                all_Scores.append(Score_value)\n",
    "    return all_image_addresses, all_Scores, total_image_number\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_folder, input_folders, transform =None):\n",
    "        self.img_dirs, self.scores, self.img_num = DataPrepare(root_folder, input_folders)\n",
    "        self.transform = transform\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.img_num\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_dirs[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        score = self.scores[idx] / 1500\n",
    "        return image, score\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "traindataset = ImageDataset(root_folder, training_folders, transform=general_transform)\n",
    "traindataloader= DataLoader(traindataset, batch_size=32, shuffle=True)\n",
    "\n",
    "evaluatedataset= ImageDataset(root_folder, testing_folders, transform=general_transform)\n",
    "evaluatedataloader= DataLoader(evaluatedataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "   #load pretrained resnet model\n",
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "vgg16 = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "alexnet = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "\n",
    "num_features = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_features,1) #output 1 for regression\n",
    "\n",
    "num_features_vgg = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_features_vgg, 1)\n",
    "\n",
    "num_features_alexnet = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Linear(num_features_alexnet, 1)\n",
    "\n",
    "\n",
    "#LOAD IN THE GPU (MUY IMPORTANTE NO OLVIDES)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "vgg16 = vgg16.to(device)\n",
    "alexnet = alexnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset on model: ResNet\n",
      "Epoch [1/65], Loss: 0.9362\n",
      "Epoch [2/65], Loss: 0.0104\n",
      "Epoch [3/65], Loss: 0.0042\n",
      "Epoch [4/65], Loss: 0.0029\n",
      "Epoch [5/65], Loss: 0.0028\n",
      "Epoch [6/65], Loss: 0.0024\n",
      "Epoch [7/65], Loss: 0.0023\n",
      "Epoch [8/65], Loss: 0.0020\n",
      "Epoch [9/65], Loss: 0.0019\n",
      "Epoch [10/65], Loss: 0.0025\n",
      "Epoch [11/65], Loss: 0.0017\n",
      "Epoch [12/65], Loss: 0.0019\n",
      "Epoch [13/65], Loss: 0.0019\n",
      "Epoch [14/65], Loss: 0.0015\n",
      "Epoch [15/65], Loss: 0.0014\n",
      "Epoch [16/65], Loss: 0.0016\n",
      "Epoch [17/65], Loss: 0.0014\n",
      "Epoch [18/65], Loss: 0.0013\n",
      "Epoch [19/65], Loss: 0.0022\n",
      "Epoch [20/65], Loss: 0.0026\n",
      "Epoch [21/65], Loss: 0.0009\n",
      "Epoch [22/65], Loss: 0.0007\n",
      "Epoch [23/65], Loss: 0.0008\n",
      "Epoch [24/65], Loss: 0.0009\n",
      "Epoch [25/65], Loss: 0.0007\n",
      "Epoch [26/65], Loss: 0.0007\n",
      "Epoch [27/65], Loss: 0.0007\n",
      "Epoch [28/65], Loss: 0.0006\n",
      "Epoch [29/65], Loss: 0.0007\n",
      "Epoch [30/65], Loss: 0.0006\n",
      "Epoch [31/65], Loss: 0.0006\n",
      "Epoch [32/65], Loss: 0.0007\n",
      "Epoch [33/65], Loss: 0.0007\n",
      "Epoch [34/65], Loss: 0.0006\n",
      "Epoch [35/65], Loss: 0.0006\n",
      "Epoch [36/65], Loss: 0.0006\n",
      "Epoch [37/65], Loss: 0.0007\n",
      "Epoch [38/65], Loss: 0.0005\n",
      "Epoch [39/65], Loss: 0.0007\n",
      "Epoch [40/65], Loss: 0.0008\n",
      "Epoch [41/65], Loss: 0.0007\n",
      "Epoch [42/65], Loss: 0.0005\n",
      "Epoch [43/65], Loss: 0.0005\n",
      "Epoch [44/65], Loss: 0.0005\n",
      "Epoch [45/65], Loss: 0.0006\n",
      "Epoch [46/65], Loss: 0.0005\n",
      "Epoch [47/65], Loss: 0.0005\n",
      "Epoch [48/65], Loss: 0.0005\n",
      "Epoch [49/65], Loss: 0.0005\n",
      "Epoch [50/65], Loss: 0.0005\n",
      "Epoch [51/65], Loss: 0.0006\n",
      "Epoch [52/65], Loss: 0.0006\n",
      "Epoch [53/65], Loss: 0.0004\n",
      "Epoch [54/65], Loss: 0.0005\n",
      "Epoch [55/65], Loss: 0.0005\n",
      "Epoch [56/65], Loss: 0.0005\n",
      "Epoch [57/65], Loss: 0.0005\n",
      "Epoch [58/65], Loss: 0.0004\n",
      "Epoch [59/65], Loss: 0.0005\n",
      "Epoch [60/65], Loss: 0.0005\n",
      "Epoch [61/65], Loss: 0.0005\n",
      "Epoch [62/65], Loss: 0.0005\n",
      "Epoch [63/65], Loss: 0.0005\n",
      "Epoch [64/65], Loss: 0.0005\n",
      "Epoch [65/65], Loss: 0.0005\n",
      "Training completed! for (ResNet)\n",
      "Training dataset on model: VGG\n",
      "Epoch [1/65], Loss: 0.0005\n",
      "Epoch [2/65], Loss: 0.0005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     34\u001b[0m resnet18 \u001b[38;5;241m=\u001b[39m train_model(resnet18, \u001b[38;5;241m65\u001b[39m, traindataloader)\n\u001b[0;32m---> 35\u001b[0m vgg16 \u001b[38;5;241m=\u001b[39m train_model(vgg16, \u001b[38;5;241m65\u001b[39m, traindataloader)\n\u001b[1;32m     36\u001b[0m alexnet \u001b[38;5;241m=\u001b[39m train_model(alexnet, \u001b[38;5;241m65\u001b[39m, traindataloader)\n",
      "Cell \u001b[0;32mIn[50], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, dataloader)\u001b[0m\n\u001b[1;32m     22\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, num_epochs, dataloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "    num_epochs = 65\n",
    "    model_name = model.__class__.__name__  # Get the model class name\n",
    "    print(f\"Training dataset on model: {model_name}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss =0.0\n",
    "        for images, scores in dataloader:\n",
    "            images = images.to(device)\n",
    "            scores = scores.to(device).view(-1,1).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = resnet18(images)\n",
    "            loss = criterion(outputs, scores)\n",
    "            \n",
    "            #backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
    "        \n",
    "    print(f'Training completed! for ({model_name})')\n",
    "    return model\n",
    "\n",
    "resnet18 = train_model(resnet18, 65, traindataloader)\n",
    "vgg16 = train_model(vgg16, 65, traindataloader)\n",
    "alexnet = train_model(alexnet, 65, traindataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.038317673"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model_name = model.__class__.__name__  # Get the model class name\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for images, scores in dataloader:\n",
    "            images = images.to(device)\n",
    "            scores = scores.to(device).view(-1,1).float()\n",
    "            outputs = model(images)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_scores.append(scores.cpu().numpy())\n",
    "            \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_scores = np.concatenate(all_scores)\n",
    "    mse = mean_squared_error(all_scores, all_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(f'RMSE ({model_name}): {rmse*1500:.4f}')\n",
    "    return rmse\n",
    "\n",
    "evaluate_model(resnet18, evaluatedataloader)\n",
    "evaluate_model(vgg16, evaluatedataloader)\n",
    "evaluate_model(alexnet, evaluatedataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc / Junk Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
