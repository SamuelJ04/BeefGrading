{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model for USDA Beef Grading\n",
    "\n",
    "This model will use pytoch and resnet to make a CNN regression model (convolutional neural network)\n",
    "hay que mantener 5 pasos\n",
    "1. cargando imagenes y procesarlos\n",
    "2. modificar el modelo resnet para la regresion\n",
    "3. entrenar el model\n",
    "4. evaluar modelo (root mean square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder =  \"Data/Cleaned JPEG Images\"\n",
    "training_folders = [\n",
    "    \"Cargill Dodge 07 20 22 Plant\", \n",
    "    \"Cargill Fort Morgan 03 28 22 Plant\",\n",
    "    \"Cargill Schuyler 04 01 22 Plant\",\n",
    "    \"Cargill Fort Morgan 07 15 22 Plant\"\n",
    "]\n",
    "\n",
    "testing_folders= [\n",
    "    \"Cargill Friona 07 18 22 Plant\",\n",
    "    \"Cargill Schuyler 07 18 22 Plant\",\n",
    "    \"Cargill Fort Morgan 05 12 22 Plant\",\n",
    "]\n",
    "#df = pd.read_excel(excel_path)\n",
    "\n",
    "#df.columns = df.columns.str.strip()\n",
    "#ID_to_score = dict(zip(df['CarcassId'], df['Average']))\n",
    "#ID_to_score = {f\"{carcass_id}.jpg\": avg for carcass_id, avg in zip(df['ID'], df['AVG'])}\n",
    "\n",
    "#print(ID_to_score.keys())\n",
    "\n",
    "def DataPrepare(root_folder, input_folders):\n",
    "    all_image_addresses= []\n",
    "    all_Scores = []\n",
    "    total_image_number = 0\n",
    "    for i in range((len(input_folders))):\n",
    "        img_folder_name = root_folder + \"/\" +  input_folders[i] + \"/Images/\"\n",
    "        print(img_folder_name)\n",
    "        Scores_name = root_folder + \"/\" + input_folders[i] + \"/data.xlsx\"\n",
    "        print(Scores_name)\n",
    "        df = pd.read_excel(Scores_name)\n",
    "        for _, _, files in os.walk(img_folder_name):\n",
    "            for filename in files:\n",
    "                total_image_number += 1\n",
    "                all_image_addresses.append(img_folder_name + filename)\n",
    "                Score_value = df.at[int(df.index[df['ID'] == filename[0:-4]][0]), 'AVG']\n",
    "                all_Scores.append(Score_value)\n",
    "    return all_image_addresses, all_Scores, total_image_number\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_folder, input_folders, transform =None):\n",
    "        self.img_dirs, self.scores, self.img_num = DataPrepare(root_folder, input_folders)\n",
    "        self.transform = transform\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.img_num\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_dirs[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        score = self.scores[idx] / 1500\n",
    "        return image, score\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Cleaned JPEG Images/Cargill Dodge 07 20 22 Plant/Images/\n",
      "Data/Cleaned JPEG Images/Cargill Dodge 07 20 22 Plant/data.xlsx\n",
      "Data/Cleaned JPEG Images/Cargill Fort Morgan 03 28 22 Plant/Images/\n",
      "Data/Cleaned JPEG Images/Cargill Fort Morgan 03 28 22 Plant/data.xlsx\n",
      "Data/Cleaned JPEG Images/Cargill Schuyler 04 01 22 Plant/Images/\n",
      "Data/Cleaned JPEG Images/Cargill Schuyler 04 01 22 Plant/data.xlsx\n",
      "Data/Cleaned JPEG Images/Cargill Fort Morgan 07 15 22 Plant/Images/\n",
      "Data/Cleaned JPEG Images/Cargill Fort Morgan 07 15 22 Plant/data.xlsx\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.485\u001b[39m,\u001b[38;5;241m0.456\u001b[39m,\u001b[38;5;241m0.406\u001b[39m], [\u001b[38;5;241m0.229\u001b[39m,\u001b[38;5;241m0.224\u001b[39m,\u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      7\u001b[0m traindataset \u001b[38;5;241m=\u001b[39m ImageDataset(root_folder, training_folders, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m----> 8\u001b[0m dataloader\u001b[38;5;241m=\u001b[39m DataLoader(traindataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/beefproject/lib/python3.12/site-packages/torch/utils/data/dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/beefproject/lib/python3.12/site-packages/torch/utils/data/sampler.py:144\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "traindataset = ImageDataset(root_folder, training_folders, transform=transform)\n",
    "dataloader= DataLoader(traindataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "   #load pretrained resnet model\n",
    "resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_features,1) #output 1 for regression\n",
    "\n",
    "#LOAD IN THE GPU (MUY IMPORTANTE NO OLVIDES)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      8\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, scores \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     10\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr = 0.001)\n",
    "scheduler = StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "\n",
    "num_epochs = 65\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss =0.0\n",
    "    for images, scores in dataloader:\n",
    "        images = images.to(device)\n",
    "        scores = scores.to(device).view(-1,1).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, scores)\n",
    "        \n",
    "        #backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
    "    \n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 31.2301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.230062"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for images, scores in dataloader:\n",
    "            images = images.to(device)\n",
    "            scores = scores.to(device).view(-1,1).float()\n",
    "            outputs = model(images)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_scores.append(scores.cpu().numpy())\n",
    "            \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_scores = np.concatenate(all_scores)\n",
    "    mse = mean_squared_error(all_scores, all_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    return rmse\n",
    "\n",
    "evaluate_model(resnet, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc / Junk Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
